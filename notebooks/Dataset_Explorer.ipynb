{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Explorer\n",
        "This Colab Notebook was created for quickly investigating classification datasets that exist in UCI machine learning repository. It provides two functions:\n",
        "1. Quick analysis of a dataset using pandas profiling\n",
        "2. Creation of neural networks via keras tuner library to automatically identifying nearly optimal hyperparameters in order to gain insight on the expected success levels for a dataset.\n",
        "\n",
        "The notebook already contains links to some of the investigated datasets to provide information on how it's used."
      ],
      "metadata": {
        "id": "cQyonHKWnlfm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNd0najrNzOF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb0e7781-d7d0-4b05-ed04-9495ce357aba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     | 21.8 MB 143 kB/s\n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 10.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 40.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 102 kB 51.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 690 kB 44.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 19.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 812 kB 50.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 38.1 MB 1.3 MB/s \n",
            "\u001b[?25h  Building wheel for pandas-profiling (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for imagehash (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -q https://github.com/pandas-profiling/pandas-profiling/archive/master.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7shF1Oi8OO0K"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pandas_profiling import ProfileReport"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9fv0WUhOXlO"
      },
      "outputs": [],
      "source": [
        "abalone = 'https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data' # very low level of accuracy possible from the start\n",
        "cars = 'https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data'\n",
        "glass = 'https://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data'\n",
        "ionosphere = 'https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data'\n",
        "soybean = 'https://archive.ics.uci.edu/ml/machine-learning-databases/soybean/soybean-large.data' # a lot of classes to classify\n",
        "arrythmia = 'https://archive.ics.uci.edu/ml/machine-learning-databases/arrhythmia/arrhythmia.data'\n",
        "sonar = 'https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data' #might be too complex to achieve with a small dataset\n",
        "congress = 'https://archive.ics.uci.edu/ml/machine-learning-databases/voting-records/house-votes-84.data'\n",
        "echocardiogram = 'https://archive.ics.uci.edu/ml/machine-learning-databases/echocardiogram/echocardiogram.data' # data cannot be parsed easily"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "4sLGDcnIS3NC",
        "outputId": "075f7078-77ed-4aa8-836c-6bcdd55f6200"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0            1            2            3            4            5  \\\n",
              "count   4177  4177.000000  4177.000000  4177.000000  4177.000000  4177.000000   \n",
              "unique     3          NaN          NaN          NaN          NaN          NaN   \n",
              "top        M          NaN          NaN          NaN          NaN          NaN   \n",
              "freq    1528          NaN          NaN          NaN          NaN          NaN   \n",
              "mean     NaN     0.523992     0.407881     0.139516     0.828742     0.359367   \n",
              "std      NaN     0.120093     0.099240     0.041827     0.490389     0.221963   \n",
              "min      NaN     0.075000     0.055000     0.000000     0.002000     0.001000   \n",
              "25%      NaN     0.450000     0.350000     0.115000     0.441500     0.186000   \n",
              "50%      NaN     0.545000     0.425000     0.140000     0.799500     0.336000   \n",
              "75%      NaN     0.615000     0.480000     0.165000     1.153000     0.502000   \n",
              "max      NaN     0.815000     0.650000     1.130000     2.825500     1.488000   \n",
              "\n",
              "                  6            7            8  \n",
              "count   4177.000000  4177.000000  4177.000000  \n",
              "unique          NaN          NaN          NaN  \n",
              "top             NaN          NaN          NaN  \n",
              "freq            NaN          NaN          NaN  \n",
              "mean       0.180594     0.238831     9.933684  \n",
              "std        0.109614     0.139203     3.224169  \n",
              "min        0.000500     0.001500     1.000000  \n",
              "25%        0.093500     0.130000     8.000000  \n",
              "50%        0.171000     0.234000     9.000000  \n",
              "75%        0.253000     0.329000    11.000000  \n",
              "max        0.760000     1.005000    29.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f8742187-5f34-4ee4-9ba0-0a2448d7e7e2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4177</td>\n",
              "      <td>4177.000000</td>\n",
              "      <td>4177.000000</td>\n",
              "      <td>4177.000000</td>\n",
              "      <td>4177.000000</td>\n",
              "      <td>4177.000000</td>\n",
              "      <td>4177.000000</td>\n",
              "      <td>4177.000000</td>\n",
              "      <td>4177.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>M</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1528</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.523992</td>\n",
              "      <td>0.407881</td>\n",
              "      <td>0.139516</td>\n",
              "      <td>0.828742</td>\n",
              "      <td>0.359367</td>\n",
              "      <td>0.180594</td>\n",
              "      <td>0.238831</td>\n",
              "      <td>9.933684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.120093</td>\n",
              "      <td>0.099240</td>\n",
              "      <td>0.041827</td>\n",
              "      <td>0.490389</td>\n",
              "      <td>0.221963</td>\n",
              "      <td>0.109614</td>\n",
              "      <td>0.139203</td>\n",
              "      <td>3.224169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.075000</td>\n",
              "      <td>0.055000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>0.115000</td>\n",
              "      <td>0.441500</td>\n",
              "      <td>0.186000</td>\n",
              "      <td>0.093500</td>\n",
              "      <td>0.130000</td>\n",
              "      <td>8.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.545000</td>\n",
              "      <td>0.425000</td>\n",
              "      <td>0.140000</td>\n",
              "      <td>0.799500</td>\n",
              "      <td>0.336000</td>\n",
              "      <td>0.171000</td>\n",
              "      <td>0.234000</td>\n",
              "      <td>9.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.615000</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>0.165000</td>\n",
              "      <td>1.153000</td>\n",
              "      <td>0.502000</td>\n",
              "      <td>0.253000</td>\n",
              "      <td>0.329000</td>\n",
              "      <td>11.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.815000</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>1.130000</td>\n",
              "      <td>2.825500</td>\n",
              "      <td>1.488000</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>1.005000</td>\n",
              "      <td>29.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8742187-5f34-4ee4-9ba0-0a2448d7e7e2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f8742187-5f34-4ee4-9ba0-0a2448d7e7e2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f8742187-5f34-4ee4-9ba0-0a2448d7e7e2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "inspected = abalone\n",
        "pandas_i = pd.read_csv(inspected,header = None)\n",
        "pandas_i.describe(include = 'all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "N1LATPXlZkWP",
        "outputId": "045fc1bf-7a80-4013-da8f-beda13aa891a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      0      1      2      3       4       5       6       7   8\n",
              "0     M  0.455  0.365  0.095  0.5140  0.2245  0.1010  0.1500  15\n",
              "1     M  0.350  0.265  0.090  0.2255  0.0995  0.0485  0.0700   7\n",
              "2     F  0.530  0.420  0.135  0.6770  0.2565  0.1415  0.2100   9\n",
              "3     M  0.440  0.365  0.125  0.5160  0.2155  0.1140  0.1550  10\n",
              "4     I  0.330  0.255  0.080  0.2050  0.0895  0.0395  0.0550   7\n",
              "...  ..    ...    ...    ...     ...     ...     ...     ...  ..\n",
              "4172  F  0.565  0.450  0.165  0.8870  0.3700  0.2390  0.2490  11\n",
              "4173  M  0.590  0.440  0.135  0.9660  0.4390  0.2145  0.2605  10\n",
              "4174  M  0.600  0.475  0.205  1.1760  0.5255  0.2875  0.3080   9\n",
              "4175  F  0.625  0.485  0.150  1.0945  0.5310  0.2610  0.2960  10\n",
              "4176  M  0.710  0.555  0.195  1.9485  0.9455  0.3765  0.4950  12\n",
              "\n",
              "[4177 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f62dec79-2ae9-46c5-a624-ee933bf7f61c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>0.455</td>\n",
              "      <td>0.365</td>\n",
              "      <td>0.095</td>\n",
              "      <td>0.5140</td>\n",
              "      <td>0.2245</td>\n",
              "      <td>0.1010</td>\n",
              "      <td>0.1500</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M</td>\n",
              "      <td>0.350</td>\n",
              "      <td>0.265</td>\n",
              "      <td>0.090</td>\n",
              "      <td>0.2255</td>\n",
              "      <td>0.0995</td>\n",
              "      <td>0.0485</td>\n",
              "      <td>0.0700</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>F</td>\n",
              "      <td>0.530</td>\n",
              "      <td>0.420</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.6770</td>\n",
              "      <td>0.2565</td>\n",
              "      <td>0.1415</td>\n",
              "      <td>0.2100</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M</td>\n",
              "      <td>0.440</td>\n",
              "      <td>0.365</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.5160</td>\n",
              "      <td>0.2155</td>\n",
              "      <td>0.1140</td>\n",
              "      <td>0.1550</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I</td>\n",
              "      <td>0.330</td>\n",
              "      <td>0.255</td>\n",
              "      <td>0.080</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.0895</td>\n",
              "      <td>0.0395</td>\n",
              "      <td>0.0550</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4172</th>\n",
              "      <td>F</td>\n",
              "      <td>0.565</td>\n",
              "      <td>0.450</td>\n",
              "      <td>0.165</td>\n",
              "      <td>0.8870</td>\n",
              "      <td>0.3700</td>\n",
              "      <td>0.2390</td>\n",
              "      <td>0.2490</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4173</th>\n",
              "      <td>M</td>\n",
              "      <td>0.590</td>\n",
              "      <td>0.440</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.9660</td>\n",
              "      <td>0.4390</td>\n",
              "      <td>0.2145</td>\n",
              "      <td>0.2605</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4174</th>\n",
              "      <td>M</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.475</td>\n",
              "      <td>0.205</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>0.5255</td>\n",
              "      <td>0.2875</td>\n",
              "      <td>0.3080</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4175</th>\n",
              "      <td>F</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.485</td>\n",
              "      <td>0.150</td>\n",
              "      <td>1.0945</td>\n",
              "      <td>0.5310</td>\n",
              "      <td>0.2610</td>\n",
              "      <td>0.2960</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4176</th>\n",
              "      <td>M</td>\n",
              "      <td>0.710</td>\n",
              "      <td>0.555</td>\n",
              "      <td>0.195</td>\n",
              "      <td>1.9485</td>\n",
              "      <td>0.9455</td>\n",
              "      <td>0.3765</td>\n",
              "      <td>0.4950</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4177 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f62dec79-2ae9-46c5-a624-ee933bf7f61c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f62dec79-2ae9-46c5-a624-ee933bf7f61c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f62dec79-2ae9-46c5-a624-ee933bf7f61c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "pandas_i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmni6A8HTb7R"
      },
      "outputs": [],
      "source": [
        "#minimal = False\n",
        "#if len(pandas_i.columns) > 25:\n",
        "#  minimal = True\n",
        "#profile = ProfileReport(pandas_i)#, minimal=minimal)\n",
        "#profile.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_s8ifypknYdX",
        "outputId": "235d749f-6200-40fb-9dc0-c5696de2367f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 19.2 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 40 kB 3.5 MB/s eta 0:00:01\r\u001b[K     |██████                          | 51 kB 3.5 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 61 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 71 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 81 kB 3.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 92 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 102 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 112 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 122 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 133 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 143 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 153 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 163 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 174 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 184 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 194 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 204 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 215 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 225 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 235 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 245 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 256 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 266 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 268 kB 4.1 MB/s \n",
            "\u001b[?25h  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 462 kB 6.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 133 kB 4.4 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q pyyaml==5.3\n",
        "!pip install -q scikeras[tensorflow]\n",
        "!pip install -q keras-tuner\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLS_imPCUCD7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "377dc204-d957-4650-a871-7620638183f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  defaults = yaml.load(f)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "#from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras import layers\n",
        "import keras_tuner as kt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSbdBtKXgS4o"
      },
      "outputs": [],
      "source": [
        "# load and process the dataset\n",
        "def load_dataset(pandas_df):\n",
        "\t# load the dataset as a pandas DataFrame\n",
        "  #pandas_df = pandas_df.drop('date', axis=1)\n",
        "  # retrieve numpy array\n",
        "  dataset = pandas_df.values\n",
        "  X = dataset[:, :-1]\n",
        "  Y = dataset[:,-1]\n",
        "\t# format all fields as string\n",
        "  X = X.astype(str)\n",
        "\t# reshape target to be a 2d array\n",
        "  Y = Y.reshape((len(Y), 1))\n",
        "  return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2RecFUqhd_L"
      },
      "outputs": [],
      "source": [
        "# prepare input data\n",
        "def prepare_inputs(X_train, X_test):\n",
        "\tohe = OneHotEncoder(sparse=False)\n",
        "\tohe.fit(X_train)\n",
        "\tX_train_enc = ohe.transform(X_train)\n",
        "\tX_test_enc = ohe.transform(X_test)\n",
        "\treturn X_train_enc, X_test_enc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caQPoZ_AeDXc",
        "outputId": "b84aad0a-8b99-4ae4-dca9-a8525a536517"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "cols = pandas_i.columns.tolist()\n",
        "cols = cols[1:] + [0]\n",
        "cols"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pandas_i = pandas_i[cols]\n",
        "pandas_i"
      ],
      "metadata": {
        "id": "TyfmCcSpKyQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pandas_i2 = pandas_i.replace({'republican' : 0, 'democrat' : 1, 'y': 1,'n':0, '?':3})\n",
        "pandas_i2"
      ],
      "metadata": {
        "id": "9JEpK5tuclST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psKqPBZxh31Q",
        "outputId": "89b565d7-aebc-447b-8104-3075c009091b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "x,y = load_dataset(pandas_i2)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=5)\n",
        "y_train[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h40JzVa7Z1hs"
      },
      "outputs": [],
      "source": [
        "x_train, x_test = prepare_inputs(x_train, x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBt73wd6hDcM"
      },
      "outputs": [],
      "source": [
        "y_train, y_test = prepare_inputs(y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXr6zGGvqh1p"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.astype('float')\n",
        "y_train = y_train.astype('int')\n",
        "x_test = x_test.astype('float')\n",
        "y_test = y_test.astype('int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DL5ezAVab8I",
        "outputId": "38961821-5454-4a2c-e37c-5a2860f98591"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "y_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWUiBAjja613",
        "outputId": "098157fa-396f-4b01-a094-3e0ea11a2866"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
              "       0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "x_test[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFN_qW8yRpKE"
      },
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Flatten())\n",
        "    # Tune the number of layers.\n",
        "    for i in range(hp.Int(\"num_layers\", 1, 4)):\n",
        "        model.add(\n",
        "            layers.Dense(\n",
        "                # Tune number of units separately.\n",
        "                units=hp.Int(f\"units_{i}\", min_value=32, max_value=512, step=32),\n",
        "                activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),\n",
        "            )\n",
        "        )\n",
        "    if hp.Boolean(\"dropout\"):\n",
        "        model.add(layers.Dropout(rate=0.25))\n",
        "    model.add(layers.Dense(len(y_train[0]), activation=\"softmax\"))\n",
        "    learning_rate = hp.Float(\"lr\", min_value=1e-5, max_value=1e-2, sampling=\"log\")\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "    build_model(kt.HyperParameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkP4a9n3TDie",
        "outputId": "48ca9177-f4a7-40b2-a322-b07462908601"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 5\n",
            "num_layers (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 4, 'step': 1, 'sampling': None}\n",
            "units_0 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "activation (Choice)\n",
            "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh'], 'ordered': False}\n",
            "dropout (Boolean)\n",
            "{'default': False, 'conditions': []}\n",
            "lr (Float)\n",
            "{'default': 1e-05, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n"
          ]
        }
      ],
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "tuner = kt.RandomSearch(\n",
        "    hypermodel=build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=500,\n",
        "    executions_per_trial=2,\n",
        "    overwrite=True,\n",
        "    directory=\"my_dir\",\n",
        "    project_name=\"helloworld\",\n",
        ")\n",
        "tuner.search_space_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sq5I8oABT2es",
        "outputId": "d4dbe17a-5bfc-424a-a74f-58d9201340c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 306 Complete [00h 00m 08s]\n",
            "val_accuracy: 0.9431818127632141\n",
            "\n",
            "Best val_accuracy So Far: 0.9772727489471436\n",
            "Total elapsed time: 00h 53m 30s\n",
            "\n",
            "Search: Running Trial #307\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "2                 |2                 |num_layers\n",
            "480               |64                |units_0\n",
            "tanh              |relu              |activation\n",
            "False             |False             |dropout\n",
            "1.1836e-05        |0.0012201         |lr\n",
            "192               |64                |units_1\n",
            "96                |352               |units_2\n",
            "64                |64                |units_3\n",
            "\n",
            "Epoch 1/100\n",
            "13/13 [==============================] - 1s 21ms/step - loss: 0.6671 - accuracy: 0.5550 - val_loss: 0.5852 - val_accuracy: 0.7500\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.6000 - accuracy: 0.6777 - val_loss: 0.5246 - val_accuracy: 0.7727\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.5445 - accuracy: 0.7545 - val_loss: 0.4759 - val_accuracy: 0.7955\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4975 - accuracy: 0.8338 - val_loss: 0.4357 - val_accuracy: 0.7955\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.4575 - accuracy: 0.8568 - val_loss: 0.4022 - val_accuracy: 0.8409\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4249 - accuracy: 0.8670 - val_loss: 0.3747 - val_accuracy: 0.8409\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.3977 - accuracy: 0.8875 - val_loss: 0.3518 - val_accuracy: 0.8636\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.3744 - accuracy: 0.8951 - val_loss: 0.3331 - val_accuracy: 0.8636\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.3550 - accuracy: 0.8926 - val_loss: 0.3175 - val_accuracy: 0.8636\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.3380 - accuracy: 0.8926 - val_loss: 0.3042 - val_accuracy: 0.8636\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.3238 - accuracy: 0.8977 - val_loss: 0.2927 - val_accuracy: 0.8636\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.3110 - accuracy: 0.8951 - val_loss: 0.2822 - val_accuracy: 0.8636\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2991 - accuracy: 0.9003 - val_loss: 0.2730 - val_accuracy: 0.8636\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2886 - accuracy: 0.9003 - val_loss: 0.2651 - val_accuracy: 0.8636\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2794 - accuracy: 0.9028 - val_loss: 0.2581 - val_accuracy: 0.8636\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2709 - accuracy: 0.9003 - val_loss: 0.2517 - val_accuracy: 0.8636\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2631 - accuracy: 0.9003 - val_loss: 0.2458 - val_accuracy: 0.8636\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2556 - accuracy: 0.9028 - val_loss: 0.2408 - val_accuracy: 0.8636\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.2493 - accuracy: 0.9028 - val_loss: 0.2358 - val_accuracy: 0.9091\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2429 - accuracy: 0.9028 - val_loss: 0.2316 - val_accuracy: 0.9091\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2375 - accuracy: 0.9054 - val_loss: 0.2279 - val_accuracy: 0.9091\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2319 - accuracy: 0.9079 - val_loss: 0.2238 - val_accuracy: 0.9091\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2267 - accuracy: 0.9130 - val_loss: 0.2203 - val_accuracy: 0.9091\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2220 - accuracy: 0.9105 - val_loss: 0.2165 - val_accuracy: 0.9091\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2173 - accuracy: 0.9207 - val_loss: 0.2130 - val_accuracy: 0.9091\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2129 - accuracy: 0.9207 - val_loss: 0.2096 - val_accuracy: 0.9091\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2088 - accuracy: 0.9207 - val_loss: 0.2069 - val_accuracy: 0.9091\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.2050 - accuracy: 0.9207 - val_loss: 0.2039 - val_accuracy: 0.9091\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2011 - accuracy: 0.9233 - val_loss: 0.2011 - val_accuracy: 0.9091\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1974 - accuracy: 0.9258 - val_loss: 0.1987 - val_accuracy: 0.9091\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1940 - accuracy: 0.9309 - val_loss: 0.1962 - val_accuracy: 0.9091\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1907 - accuracy: 0.9309 - val_loss: 0.1938 - val_accuracy: 0.9091\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1874 - accuracy: 0.9361 - val_loss: 0.1918 - val_accuracy: 0.9091\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1843 - accuracy: 0.9361 - val_loss: 0.1900 - val_accuracy: 0.9091\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1814 - accuracy: 0.9386 - val_loss: 0.1879 - val_accuracy: 0.9091\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.1784 - accuracy: 0.9386 - val_loss: 0.1857 - val_accuracy: 0.9091\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1756 - accuracy: 0.9412 - val_loss: 0.1836 - val_accuracy: 0.9091\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1730 - accuracy: 0.9437 - val_loss: 0.1816 - val_accuracy: 0.9091\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.1706 - accuracy: 0.9463 - val_loss: 0.1792 - val_accuracy: 0.9091\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1678 - accuracy: 0.9514 - val_loss: 0.1775 - val_accuracy: 0.9091\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1653 - accuracy: 0.9514 - val_loss: 0.1758 - val_accuracy: 0.9091\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1629 - accuracy: 0.9488 - val_loss: 0.1743 - val_accuracy: 0.9091\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1606 - accuracy: 0.9488 - val_loss: 0.1731 - val_accuracy: 0.9091\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1583 - accuracy: 0.9540 - val_loss: 0.1714 - val_accuracy: 0.9091\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1561 - accuracy: 0.9540 - val_loss: 0.1698 - val_accuracy: 0.9091\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1542 - accuracy: 0.9540 - val_loss: 0.1685 - val_accuracy: 0.9091\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1521 - accuracy: 0.9540 - val_loss: 0.1679 - val_accuracy: 0.9091\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1501 - accuracy: 0.9540 - val_loss: 0.1667 - val_accuracy: 0.9091\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1482 - accuracy: 0.9540 - val_loss: 0.1658 - val_accuracy: 0.9091\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1465 - accuracy: 0.9540 - val_loss: 0.1646 - val_accuracy: 0.9091\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.1445 - accuracy: 0.9540 - val_loss: 0.1628 - val_accuracy: 0.9091\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1427 - accuracy: 0.9540 - val_loss: 0.1621 - val_accuracy: 0.9091\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1409 - accuracy: 0.9514 - val_loss: 0.1611 - val_accuracy: 0.9318\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1391 - accuracy: 0.9514 - val_loss: 0.1597 - val_accuracy: 0.9318\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1373 - accuracy: 0.9514 - val_loss: 0.1585 - val_accuracy: 0.9318\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1357 - accuracy: 0.9514 - val_loss: 0.1573 - val_accuracy: 0.9318\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1341 - accuracy: 0.9514 - val_loss: 0.1567 - val_accuracy: 0.9318\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1326 - accuracy: 0.9514 - val_loss: 0.1557 - val_accuracy: 0.9318\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1309 - accuracy: 0.9514 - val_loss: 0.1548 - val_accuracy: 0.9318\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1293 - accuracy: 0.9514 - val_loss: 0.1544 - val_accuracy: 0.9318\n",
            "Epoch 61/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1278 - accuracy: 0.9540 - val_loss: 0.1534 - val_accuracy: 0.9318\n",
            "Epoch 62/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1263 - accuracy: 0.9540 - val_loss: 0.1521 - val_accuracy: 0.9318\n",
            "Epoch 63/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1248 - accuracy: 0.9540 - val_loss: 0.1510 - val_accuracy: 0.9318\n",
            "Epoch 64/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1235 - accuracy: 0.9540 - val_loss: 0.1504 - val_accuracy: 0.9318\n",
            "Epoch 65/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1221 - accuracy: 0.9540 - val_loss: 0.1498 - val_accuracy: 0.9318\n",
            "Epoch 66/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1209 - accuracy: 0.9565 - val_loss: 0.1484 - val_accuracy: 0.9318\n",
            "Epoch 67/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1194 - accuracy: 0.9591 - val_loss: 0.1479 - val_accuracy: 0.9318\n",
            "Epoch 68/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1183 - accuracy: 0.9565 - val_loss: 0.1480 - val_accuracy: 0.9318\n",
            "Epoch 69/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1168 - accuracy: 0.9565 - val_loss: 0.1468 - val_accuracy: 0.9318\n",
            "Epoch 70/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1157 - accuracy: 0.9565 - val_loss: 0.1456 - val_accuracy: 0.9318\n",
            "Epoch 71/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1145 - accuracy: 0.9616 - val_loss: 0.1453 - val_accuracy: 0.9318\n",
            "Epoch 72/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1134 - accuracy: 0.9616 - val_loss: 0.1450 - val_accuracy: 0.9318\n",
            "Epoch 73/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1123 - accuracy: 0.9616 - val_loss: 0.1440 - val_accuracy: 0.9318\n",
            "Epoch 74/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1110 - accuracy: 0.9616 - val_loss: 0.1436 - val_accuracy: 0.9318\n",
            "Epoch 75/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1101 - accuracy: 0.9591 - val_loss: 0.1439 - val_accuracy: 0.9318\n",
            "Epoch 76/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1089 - accuracy: 0.9591 - val_loss: 0.1429 - val_accuracy: 0.9318\n",
            "Epoch 77/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1077 - accuracy: 0.9616 - val_loss: 0.1419 - val_accuracy: 0.9318\n",
            "Epoch 78/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1067 - accuracy: 0.9642 - val_loss: 0.1415 - val_accuracy: 0.9318\n",
            "Epoch 79/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1056 - accuracy: 0.9668 - val_loss: 0.1410 - val_accuracy: 0.9318\n",
            "Epoch 80/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1047 - accuracy: 0.9668 - val_loss: 0.1406 - val_accuracy: 0.9318\n",
            "Epoch 81/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1037 - accuracy: 0.9668 - val_loss: 0.1398 - val_accuracy: 0.9318\n",
            "Epoch 82/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1030 - accuracy: 0.9668 - val_loss: 0.1397 - val_accuracy: 0.9318\n",
            "Epoch 83/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1019 - accuracy: 0.9668 - val_loss: 0.1394 - val_accuracy: 0.9318\n",
            "Epoch 84/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1010 - accuracy: 0.9668 - val_loss: 0.1388 - val_accuracy: 0.9318\n",
            "Epoch 85/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1003 - accuracy: 0.9668 - val_loss: 0.1385 - val_accuracy: 0.9318\n",
            "Epoch 86/100\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.0996 - accuracy: 0.9668 - val_loss: 0.1372 - val_accuracy: 0.9091\n",
            "Epoch 87/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0985 - accuracy: 0.9693 - val_loss: 0.1370 - val_accuracy: 0.9091\n",
            "Epoch 88/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0977 - accuracy: 0.9693 - val_loss: 0.1373 - val_accuracy: 0.9091\n",
            "Epoch 89/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0970 - accuracy: 0.9693 - val_loss: 0.1362 - val_accuracy: 0.9091\n",
            "Epoch 90/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0961 - accuracy: 0.9719 - val_loss: 0.1363 - val_accuracy: 0.9091\n",
            "Epoch 91/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0953 - accuracy: 0.9719 - val_loss: 0.1360 - val_accuracy: 0.9091\n",
            "Epoch 92/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0945 - accuracy: 0.9719 - val_loss: 0.1356 - val_accuracy: 0.9091\n",
            "Epoch 93/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0937 - accuracy: 0.9719 - val_loss: 0.1351 - val_accuracy: 0.9091\n",
            "Epoch 94/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0929 - accuracy: 0.9719 - val_loss: 0.1353 - val_accuracy: 0.9091\n",
            "Epoch 95/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0922 - accuracy: 0.9719 - val_loss: 0.1354 - val_accuracy: 0.9091\n",
            "Epoch 96/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0915 - accuracy: 0.9719 - val_loss: 0.1350 - val_accuracy: 0.9091\n",
            "Epoch 97/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.0907 - accuracy: 0.9693 - val_loss: 0.1350 - val_accuracy: 0.9091\n",
            "Epoch 98/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0901 - accuracy: 0.9693 - val_loss: 0.1345 - val_accuracy: 0.9091\n",
            "Epoch 99/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0893 - accuracy: 0.9719 - val_loss: 0.1339 - val_accuracy: 0.9091\n",
            "Epoch 100/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.0886 - accuracy: 0.9719 - val_loss: 0.1341 - val_accuracy: 0.9091\n",
            "Epoch 1/100\n",
            "13/13 [==============================] - 1s 19ms/step - loss: 0.7766 - accuracy: 0.3734 - val_loss: 0.6937 - val_accuracy: 0.5227\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.7038 - accuracy: 0.5115 - val_loss: 0.6217 - val_accuracy: 0.7045\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6388 - accuracy: 0.6522 - val_loss: 0.5612 - val_accuracy: 0.8409\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.5836 - accuracy: 0.7928 - val_loss: 0.5110 - val_accuracy: 0.8636\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.5360 - accuracy: 0.8338 - val_loss: 0.4674 - val_accuracy: 0.8864\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4960 - accuracy: 0.8747 - val_loss: 0.4311 - val_accuracy: 0.9318\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4620 - accuracy: 0.8926 - val_loss: 0.4008 - val_accuracy: 0.9091\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.4323 - accuracy: 0.8977 - val_loss: 0.3748 - val_accuracy: 0.9091\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.9003 - val_loss: 0.3531 - val_accuracy: 0.9091\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.3849 - accuracy: 0.9003 - val_loss: 0.3346 - val_accuracy: 0.9091\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3658 - accuracy: 0.9028 - val_loss: 0.3187 - val_accuracy: 0.9091\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3492 - accuracy: 0.9054 - val_loss: 0.3044 - val_accuracy: 0.9091\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.3344 - accuracy: 0.9054 - val_loss: 0.2923 - val_accuracy: 0.9091\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.3213 - accuracy: 0.9079 - val_loss: 0.2821 - val_accuracy: 0.9091\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3101 - accuracy: 0.9079 - val_loss: 0.2727 - val_accuracy: 0.9091\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2993 - accuracy: 0.9079 - val_loss: 0.2646 - val_accuracy: 0.9091\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2899 - accuracy: 0.9079 - val_loss: 0.2569 - val_accuracy: 0.9091\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2811 - accuracy: 0.9105 - val_loss: 0.2505 - val_accuracy: 0.9091\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2730 - accuracy: 0.9130 - val_loss: 0.2445 - val_accuracy: 0.9091\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.2660 - accuracy: 0.9130 - val_loss: 0.2391 - val_accuracy: 0.9318\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2591 - accuracy: 0.9105 - val_loss: 0.2336 - val_accuracy: 0.9318\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2529 - accuracy: 0.9105 - val_loss: 0.2294 - val_accuracy: 0.9318\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.2470 - accuracy: 0.9156 - val_loss: 0.2248 - val_accuracy: 0.9318\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2414 - accuracy: 0.9182 - val_loss: 0.2209 - val_accuracy: 0.9318\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2362 - accuracy: 0.9207 - val_loss: 0.2173 - val_accuracy: 0.9318\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2314 - accuracy: 0.9207 - val_loss: 0.2140 - val_accuracy: 0.9318\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2268 - accuracy: 0.9182 - val_loss: 0.2105 - val_accuracy: 0.9318\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2226 - accuracy: 0.9182 - val_loss: 0.2072 - val_accuracy: 0.9318\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2183 - accuracy: 0.9182 - val_loss: 0.2045 - val_accuracy: 0.9318\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2143 - accuracy: 0.9207 - val_loss: 0.2017 - val_accuracy: 0.9318\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2104 - accuracy: 0.9207 - val_loss: 0.1991 - val_accuracy: 0.9318\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.2069 - accuracy: 0.9258 - val_loss: 0.1968 - val_accuracy: 0.9318\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2033 - accuracy: 0.9284 - val_loss: 0.1948 - val_accuracy: 0.9318\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2001 - accuracy: 0.9284 - val_loss: 0.1929 - val_accuracy: 0.9318\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1968 - accuracy: 0.9284 - val_loss: 0.1907 - val_accuracy: 0.9318\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1937 - accuracy: 0.9361 - val_loss: 0.1887 - val_accuracy: 0.9318\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1909 - accuracy: 0.9335 - val_loss: 0.1869 - val_accuracy: 0.9318\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1878 - accuracy: 0.9361 - val_loss: 0.1843 - val_accuracy: 0.9318\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1851 - accuracy: 0.9386 - val_loss: 0.1822 - val_accuracy: 0.9318\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1820 - accuracy: 0.9386 - val_loss: 0.1800 - val_accuracy: 0.9318\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1793 - accuracy: 0.9386 - val_loss: 0.1783 - val_accuracy: 0.9318\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1773 - accuracy: 0.9386 - val_loss: 0.1764 - val_accuracy: 0.9318\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1744 - accuracy: 0.9412 - val_loss: 0.1749 - val_accuracy: 0.9318\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1720 - accuracy: 0.9412 - val_loss: 0.1734 - val_accuracy: 0.9318\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1698 - accuracy: 0.9412 - val_loss: 0.1719 - val_accuracy: 0.9318\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1674 - accuracy: 0.9437 - val_loss: 0.1704 - val_accuracy: 0.9318\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1651 - accuracy: 0.9437 - val_loss: 0.1690 - val_accuracy: 0.9318\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1630 - accuracy: 0.9437 - val_loss: 0.1679 - val_accuracy: 0.9318\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1609 - accuracy: 0.9437 - val_loss: 0.1670 - val_accuracy: 0.9318\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1588 - accuracy: 0.9437 - val_loss: 0.1656 - val_accuracy: 0.9318\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1569 - accuracy: 0.9463 - val_loss: 0.1641 - val_accuracy: 0.9318\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1548 - accuracy: 0.9463 - val_loss: 0.1631 - val_accuracy: 0.9318\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1529 - accuracy: 0.9488 - val_loss: 0.1620 - val_accuracy: 0.9318\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1510 - accuracy: 0.9488 - val_loss: 0.1611 - val_accuracy: 0.9318\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.1492 - accuracy: 0.9488 - val_loss: 0.1599 - val_accuracy: 0.9318\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1475 - accuracy: 0.9488 - val_loss: 0.1585 - val_accuracy: 0.9318\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1458 - accuracy: 0.9488 - val_loss: 0.1578 - val_accuracy: 0.9318\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1441 - accuracy: 0.9488 - val_loss: 0.1570 - val_accuracy: 0.9318\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1424 - accuracy: 0.9488 - val_loss: 0.1560 - val_accuracy: 0.9318\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1407 - accuracy: 0.9514 - val_loss: 0.1561 - val_accuracy: 0.9318\n",
            "Epoch 61/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1393 - accuracy: 0.9514 - val_loss: 0.1554 - val_accuracy: 0.9318\n",
            "Epoch 62/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1378 - accuracy: 0.9514 - val_loss: 0.1541 - val_accuracy: 0.9318\n",
            "Epoch 63/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1360 - accuracy: 0.9514 - val_loss: 0.1525 - val_accuracy: 0.9318\n",
            "Epoch 64/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1346 - accuracy: 0.9514 - val_loss: 0.1516 - val_accuracy: 0.9318\n",
            "Epoch 65/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1334 - accuracy: 0.9488 - val_loss: 0.1501 - val_accuracy: 0.9318\n",
            "Epoch 66/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1319 - accuracy: 0.9488 - val_loss: 0.1496 - val_accuracy: 0.9318\n",
            "Epoch 67/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1304 - accuracy: 0.9488 - val_loss: 0.1492 - val_accuracy: 0.9318\n",
            "Epoch 68/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1292 - accuracy: 0.9488 - val_loss: 0.1484 - val_accuracy: 0.9318\n",
            "Epoch 69/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1278 - accuracy: 0.9488 - val_loss: 0.1475 - val_accuracy: 0.9318\n",
            "Epoch 70/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1265 - accuracy: 0.9488 - val_loss: 0.1467 - val_accuracy: 0.9318\n",
            "Epoch 71/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1253 - accuracy: 0.9488 - val_loss: 0.1457 - val_accuracy: 0.9318\n",
            "Epoch 72/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1241 - accuracy: 0.9514 - val_loss: 0.1452 - val_accuracy: 0.9318\n",
            "Epoch 73/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1228 - accuracy: 0.9540 - val_loss: 0.1446 - val_accuracy: 0.9318\n",
            "Epoch 74/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1216 - accuracy: 0.9565 - val_loss: 0.1441 - val_accuracy: 0.9318\n",
            "Epoch 75/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1205 - accuracy: 0.9540 - val_loss: 0.1437 - val_accuracy: 0.9318\n",
            "Epoch 76/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1193 - accuracy: 0.9540 - val_loss: 0.1433 - val_accuracy: 0.9318\n",
            "Epoch 77/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1183 - accuracy: 0.9540 - val_loss: 0.1431 - val_accuracy: 0.9318\n",
            "Epoch 78/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1170 - accuracy: 0.9540 - val_loss: 0.1421 - val_accuracy: 0.9318\n",
            "Epoch 79/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1159 - accuracy: 0.9540 - val_loss: 0.1421 - val_accuracy: 0.9318\n",
            "Epoch 80/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1151 - accuracy: 0.9540 - val_loss: 0.1417 - val_accuracy: 0.9318\n",
            "Epoch 81/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1140 - accuracy: 0.9540 - val_loss: 0.1407 - val_accuracy: 0.9318\n",
            "Epoch 82/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1130 - accuracy: 0.9540 - val_loss: 0.1404 - val_accuracy: 0.9318\n",
            "Epoch 83/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1119 - accuracy: 0.9540 - val_loss: 0.1402 - val_accuracy: 0.9318\n",
            "Epoch 84/100\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1109 - accuracy: 0.9565 - val_loss: 0.1395 - val_accuracy: 0.9318\n",
            "Epoch 85/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1100 - accuracy: 0.9565 - val_loss: 0.1385 - val_accuracy: 0.9318\n",
            "Epoch 86/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1090 - accuracy: 0.9616 - val_loss: 0.1378 - val_accuracy: 0.9318\n",
            "Epoch 87/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1081 - accuracy: 0.9616 - val_loss: 0.1366 - val_accuracy: 0.9318\n",
            "Epoch 88/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1074 - accuracy: 0.9616 - val_loss: 0.1361 - val_accuracy: 0.9318\n",
            "Epoch 89/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1066 - accuracy: 0.9616 - val_loss: 0.1363 - val_accuracy: 0.9318\n",
            "Epoch 90/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1055 - accuracy: 0.9616 - val_loss: 0.1361 - val_accuracy: 0.9318\n",
            "Epoch 91/100\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 0.1047 - accuracy: 0.9616 - val_loss: 0.1358 - val_accuracy: 0.9318\n",
            "Epoch 92/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1039 - accuracy: 0.9616 - val_loss: 0.1350 - val_accuracy: 0.9318\n",
            "Epoch 93/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1029 - accuracy: 0.9616 - val_loss: 0.1352 - val_accuracy: 0.9091\n",
            "Epoch 94/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1021 - accuracy: 0.9642 - val_loss: 0.1347 - val_accuracy: 0.9091\n",
            "Epoch 95/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1014 - accuracy: 0.9642 - val_loss: 0.1342 - val_accuracy: 0.9091\n",
            "Epoch 96/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1006 - accuracy: 0.9642 - val_loss: 0.1345 - val_accuracy: 0.9091\n",
            "Epoch 97/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0997 - accuracy: 0.9642 - val_loss: 0.1343 - val_accuracy: 0.9318\n",
            "Epoch 98/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0990 - accuracy: 0.9642 - val_loss: 0.1346 - val_accuracy: 0.9318\n",
            "Epoch 99/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0981 - accuracy: 0.9668 - val_loss: 0.1346 - val_accuracy: 0.9318\n",
            "Epoch 100/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.0974 - accuracy: 0.9668 - val_loss: 0.1346 - val_accuracy: 0.9318\n"
          ]
        }
      ],
      "source": [
        "tuner.search(x_train, y_train, epochs=100, validation_data=(x_test, y_test), callbacks = [callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AK00e0vtX3wi",
        "outputId": "ce9c2657-bcbc-4538-dcbc-021b1911c9e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in my_dir/helloworld\n",
            "Showing 10 best trials\n",
            "<keras_tuner.engine.objective.Objective object at 0x7fb4878de290>\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 2\n",
            "units_0: 320\n",
            "activation: relu\n",
            "dropout: True\n",
            "lr: 0.00014461073827695564\n",
            "units_1: 480\n",
            "units_2: 416\n",
            "units_3: 384\n",
            "Score: 0.760869562625885\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 2\n",
            "units_0: 256\n",
            "activation: relu\n",
            "dropout: True\n",
            "lr: 0.0017479964577500906\n",
            "units_1: 288\n",
            "units_2: 416\n",
            "units_3: 160\n",
            "Score: 0.75\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 2\n",
            "units_0: 352\n",
            "activation: tanh\n",
            "dropout: True\n",
            "lr: 0.0007393556867732781\n",
            "units_1: 352\n",
            "units_2: 352\n",
            "units_3: 416\n",
            "Score: 0.75\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 1\n",
            "units_0: 352\n",
            "activation: relu\n",
            "dropout: True\n",
            "lr: 0.00010342590672055832\n",
            "units_1: 384\n",
            "units_2: 32\n",
            "units_3: 288\n",
            "Score: 0.739130437374115\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 4\n",
            "units_0: 416\n",
            "activation: tanh\n",
            "dropout: True\n",
            "lr: 0.0002496132167195124\n",
            "units_1: 384\n",
            "units_2: 352\n",
            "units_3: 288\n",
            "Score: 0.739130437374115\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 1\n",
            "units_0: 256\n",
            "activation: tanh\n",
            "dropout: False\n",
            "lr: 0.0014552951806228555\n",
            "units_1: 224\n",
            "units_2: 64\n",
            "units_3: 320\n",
            "Score: 0.739130437374115\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 1\n",
            "units_0: 384\n",
            "activation: tanh\n",
            "dropout: True\n",
            "lr: 0.0009927306381483174\n",
            "units_1: 320\n",
            "units_2: 96\n",
            "units_3: 384\n",
            "Score: 0.72826087474823\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 3\n",
            "units_0: 256\n",
            "activation: relu\n",
            "dropout: True\n",
            "lr: 0.0006163737697164882\n",
            "units_1: 320\n",
            "units_2: 256\n",
            "units_3: 160\n",
            "Score: 0.72826087474823\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 2\n",
            "units_0: 256\n",
            "activation: relu\n",
            "dropout: True\n",
            "lr: 0.00046716216457542726\n",
            "units_1: 448\n",
            "units_2: 224\n",
            "units_3: 224\n",
            "Score: 0.72826087474823\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 3\n",
            "units_0: 192\n",
            "activation: tanh\n",
            "dropout: True\n",
            "lr: 0.0005778535035447998\n",
            "units_1: 128\n",
            "units_2: 64\n",
            "units_3: 352\n",
            "Score: 0.72826087474823\n"
          ]
        }
      ],
      "source": [
        "tuner.results_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrEvWQe9UA6m",
        "outputId": "67a6b432-4a0e-4cd3-804e-adb0086378bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 9)                 0         \n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.kernel\n",
            "                                                                 \n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.bias\n",
            " dense (Dense)               (None, 128)               1280      \n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.kernel\n",
            "                                                                 \n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.bias\n",
            " dense_1 (Dense)             (None, 480)               61920     \n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-2.kernel\n",
            "                                                                 \n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-2.bias\n",
            " dense_2 (Dense)             (None, 160)               76960     \n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.kernel\n",
            "                                                                 \n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.bias\n",
            " dense_3 (Dense)             (None, 6)                 966       \n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
            "                                                                 \n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
            "=================================================================\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
            "Total params: 141,126\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
            "Trainable params: 141,126\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
            "Non-trainable params: 0\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n"
          ]
        }
      ],
      "source": [
        "models = tuner.get_best_models(num_models=2)\n",
        "best_model = models[0]\n",
        "# Build the model.\n",
        "# Needed for `Sequential` without specified `input_shape`.\n",
        "best_model.build(input_shape=(None,9))\n",
        "best_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cv74IiZuYkM2",
        "outputId": "e633ed43-13db-4bc8-cd2f-65ac5e387a08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "6/6 [==============================] - 1s 7ms/step - loss: 2.1387 - accuracy: 0.2604\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.8343 - accuracy: 0.3698\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.5223 - accuracy: 0.3385\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 1.5349 - accuracy: 0.3333\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.4286 - accuracy: 0.3802\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.4246 - accuracy: 0.3854\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 1.3484 - accuracy: 0.4323\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.2626 - accuracy: 0.4896\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.2759 - accuracy: 0.4167\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.1831 - accuracy: 0.4688\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.1163 - accuracy: 0.4740\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.1241 - accuracy: 0.4792\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.1862 - accuracy: 0.4323\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 1.0752 - accuracy: 0.5000\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.0115 - accuracy: 0.5469\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.9926 - accuracy: 0.4635\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.9906 - accuracy: 0.5260\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.9535 - accuracy: 0.5469\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.8963 - accuracy: 0.5938\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.9086 - accuracy: 0.6354\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.8957 - accuracy: 0.5625\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.8962 - accuracy: 0.5990\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.8514 - accuracy: 0.5990\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.8584 - accuracy: 0.6354\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.8532 - accuracy: 0.5990\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.9505 - accuracy: 0.5469\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.9238 - accuracy: 0.5938\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.9215 - accuracy: 0.5833\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.8697 - accuracy: 0.5469\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.8041 - accuracy: 0.6510\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.8315 - accuracy: 0.5938\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.8300 - accuracy: 0.5677\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.7880 - accuracy: 0.6354\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.7640 - accuracy: 0.6458\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.7556 - accuracy: 0.6250\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.8202 - accuracy: 0.6094\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.8645 - accuracy: 0.6042\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.7639 - accuracy: 0.6406\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.7369 - accuracy: 0.6927\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.7409 - accuracy: 0.7031\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.7238 - accuracy: 0.7135\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.7130 - accuracy: 0.6719\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6908 - accuracy: 0.7135\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.7240 - accuracy: 0.7083\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.7139 - accuracy: 0.6875\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.7943 - accuracy: 0.6406\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.7948 - accuracy: 0.6719\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.7944 - accuracy: 0.6719\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6963 - accuracy: 0.7031\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.7060 - accuracy: 0.6771\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6670 - accuracy: 0.7292\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6983 - accuracy: 0.7031\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.6613 - accuracy: 0.7292\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6586 - accuracy: 0.7500\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.6742 - accuracy: 0.7240\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.6690 - accuracy: 0.7031\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.6610 - accuracy: 0.7240\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.6979 - accuracy: 0.6719\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6583 - accuracy: 0.7135\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.6886 - accuracy: 0.6771\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.6897 - accuracy: 0.6875\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.6809 - accuracy: 0.7031\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.6906 - accuracy: 0.7031\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.6623 - accuracy: 0.7344\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.6463 - accuracy: 0.7031\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6750 - accuracy: 0.7292\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.6889 - accuracy: 0.6771\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6520 - accuracy: 0.6927\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.6497 - accuracy: 0.6719\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.6578 - accuracy: 0.7552\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6430 - accuracy: 0.7552\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.6513 - accuracy: 0.7240\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.6415 - accuracy: 0.7344\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.6314 - accuracy: 0.7656\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.6171 - accuracy: 0.7396\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.6612 - accuracy: 0.7135\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.6445 - accuracy: 0.7292\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6360 - accuracy: 0.6979\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.5934 - accuracy: 0.7656\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6026 - accuracy: 0.7396\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6495 - accuracy: 0.6979\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.7154 - accuracy: 0.6927\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.7559 - accuracy: 0.6250\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.7144 - accuracy: 0.6302\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.7064 - accuracy: 0.6771\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.6849 - accuracy: 0.7031\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.6443 - accuracy: 0.6823\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6064 - accuracy: 0.7396\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6114 - accuracy: 0.7188\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6024 - accuracy: 0.7344\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.5985 - accuracy: 0.7656\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6010 - accuracy: 0.7292\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6321 - accuracy: 0.7031\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6104 - accuracy: 0.7240\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6164 - accuracy: 0.7396\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.5984 - accuracy: 0.7500\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6102 - accuracy: 0.7344\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6446 - accuracy: 0.6979\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6387 - accuracy: 0.7083\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.6203 - accuracy: 0.6771\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc8d8aaf2d0>"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_hps = tuner.get_best_hyperparameters(5)\n",
        "# Build the model with the best hp.\n",
        "model = build_model(best_hps[0])\n",
        "model.fit(x=x_train, y=y_train, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ne31amGqv3c_",
        "outputId": "5dcf7a45-0172-4d0c-ecfc-52e58a7d1421"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (32, 9)                   0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (32, 128)                 1280      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (32, 480)                 61920     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (32, 160)                 76960     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (32, 6)                   966       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 141,126\n",
            "Trainable params: 141,126\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acu8eFK4iCU0"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(32, input_dim=x_train.shape[1], activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(64, input_dim=32, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dropout(0.15))\n",
        "model.add(Dense(16, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(len(y_train[0])))\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0vqGiCyiIEp"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=10E-6),\n",
        "              loss=tf.keras.losses.categorical_crossentropy,\n",
        "              metrics=[tf.keras.metrics.CategoricalAccuracy(name=\"categorical_accuracy\", dtype=None)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gU4FAWkSiS-m"
      },
      "outputs": [],
      "source": [
        "epoch = 100\n",
        "batch_size = 32\n",
        "x_train = np.asarray(x_train).astype('float32')\n",
        "y_train = np.asarray(y_train).astype('int')\n",
        "x_test = np.asarray(x_train).astype('float32')\n",
        "y_test = np.asarray(y_train).astype('int')\n",
        "\n",
        "model.fit(x_train, y_train, epochs=epoch, batch_size = batch_size, validation_data = (x_test,y_test),callbacks=[callback])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8siCi2TPmMfq"
      },
      "outputs": [],
      "source": [
        "def algorithm_pipeline(X_train_data, X_test_data, y_train_data, y_test_data, \n",
        "                       model, param_grid, cv=10, scoring_fit='neg_mean_squared_error',\n",
        "                       do_probabilities = False):\n",
        "    gs = GridSearchCV(\n",
        "        estimator=model,\n",
        "        param_grid=param_grid, \n",
        "        cv=cv, \n",
        "        n_jobs=-1, \n",
        "        scoring=scoring_fit,\n",
        "        verbose=10\n",
        "    )\n",
        "    fitted_model = gs.fit(X_train_data, y_train_data)\n",
        "    \n",
        "    if do_probabilities:\n",
        "      pred = fitted_model.predict_proba(X_test_data)\n",
        "    else:\n",
        "      pred = fitted_model.predict(X_test_data)\n",
        "    \n",
        "    return fitted_model, pred, gs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUBe9crOnJUY"
      },
      "outputs": [],
      "source": [
        "hyperparameters = {\n",
        "    'activation' : ['relu', 'elu'],\n",
        "    'learning_rate' : [0.001,0.0001,10E-5,10E-6],\n",
        "    'epochs' : [25,50,75,100,150],\n",
        "    #'optimizer' : [keras.optimizers.Adam, keras.optimizers.Nadam],\n",
        "    #'dropout_rate' : [0.1,0.15,0.20,0.25],\n",
        "    'batch_size' : [32,64],\n",
        "    'layer_1' : [32,64,128],\n",
        "    'layer_2' : [32,64,128,256]\n",
        "    #'layer_3' : [0],#,16,32,64],\n",
        "    #'layer_4' : [0]#,16,32,64]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lKPBW-ZqPAm"
      },
      "outputs": [],
      "source": [
        "def build_cnn(activation = 'relu',\n",
        "              learning_rate = 0.01,\n",
        "              layer_1 = 32,\n",
        "              layer_2 = 32,\n",
        "              layer_3 = 0,\n",
        "              layer_4 = 0,\n",
        "              dropout_rate = 0.2\n",
        "              ):\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(layer_1,input_dim = x_train.shape[1], activation=activation))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(layer_2, activation=activation))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    if layer_3 != 0:\n",
        "      model.add(Dense(layer_3, activation=activation))\n",
        "    if layer_4 != 0:\n",
        "      model.add(Dense(layer_4, activation=activation))\n",
        "    model.add(Dense(len(y_train[0])))\n",
        "    \n",
        "    model.compile(\n",
        "        loss='categorical_crossentropy', \n",
        "        optimizer=keras.optimizers.Adam(learning_rate = learning_rate), \n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "GwI081ciw-2q",
        "outputId": "dcf89577-3ad6-4aaa-c39f-a8412b0869d7"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-fb1cf4dafb8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = KerasClassifier(build_fn = build_cnn, verbose=10,activation='relu',dropout_rate = 0.1,learning_rate = 0.01,\n\u001b[0m\u001b[1;32m      2\u001b[0m               \u001b[0mlayer_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m               \u001b[0mlayer_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               \u001b[0mlayer_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m               layer_4 = 0)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'KerasClassifier' is not defined"
          ]
        }
      ],
      "source": [
        "model = KerasClassifier(build_fn = build_cnn, verbose=10,activation='relu',dropout_rate = 0.1,learning_rate = 0.01,\n",
        "              layer_1 = 32,\n",
        "              layer_2 = 32,\n",
        "              layer_3 = 0,\n",
        "              layer_4 = 0)\n",
        "\n",
        "model, pred, gss = algorithm_pipeline(x_train, x_test, y_train, y_test, model, \n",
        "                                        hyperparameters, cv=5, scoring_fit='neg_log_loss')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "VLm3ag9nwNXe",
        "outputId": "f0484a7e-5ec3-438e-9e32-e1ff347432fe"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-a803fffaa0c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mKerasClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: type object 'KerasClassifier' has no attribute 'estimator'"
          ]
        }
      ],
      "source": [
        "KerasClassifier.estimator.get_params().keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfSTzGw7mZI5"
      },
      "outputs": [],
      "source": [
        "losses = pd.DataFrame(model.history.history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "w1vReoUymcmm",
        "outputId": "03c2456a-3a48-4157-deab-6c72116bd15b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"51daeeec-89f9-4568-97d5-74b9942b20d6\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"51daeeec-89f9-4568-97d5-74b9942b20d6\")) {                    Plotly.newPlot(                        \"51daeeec-89f9-4568-97d5-74b9942b20d6\",                        [{\"hovertemplate\":\"variable=loss<br>index=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"loss\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"loss\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"xaxis\":\"x\",\"y\":[5.257571697235107,5.065102577209473,5.219379425048828,5.189451694488525,5.361777305603027,5.250916481018066,5.3497314453125,5.411423683166504,5.5378804206848145,5.422918319702148,5.460436820983887,5.476894855499268,5.217339992523193,5.681454658508301,5.5473151206970215,5.449956893920898,5.5735673904418945,5.420839309692383,5.215029239654541,5.4018073081970215,5.342228889465332,5.776516437530518,5.274796485900879,5.323772430419922,5.454401016235352,5.501620769500732,5.7312445640563965,5.694124698638916,5.612165927886963,5.549168586730957,5.827766418457031,5.278655052185059,5.323091983795166,5.612259387969971,5.615094184875488,5.37717342376709,5.134192943572998,5.737095355987549,5.350580215454102,5.420330047607422,5.408968448638916,5.70438814163208,5.2061052322387695,5.803667068481445,5.348910331726074,5.444507598876953,5.45798397064209,5.565603733062744,5.3167724609375,5.588906288146973,5.582371711730957,5.480441093444824,5.67318868637085,5.210809230804443,5.4150166511535645,5.544894218444824,5.714598655700684,5.70027494430542,5.289443492889404,5.476891040802002,5.577291011810303,5.574471950531006,5.422824382781982,5.193431854248047,5.606282711029053,5.61300802230835,5.367104530334473,5.6246795654296875,5.467478275299072,5.431785583496094,5.776847839355469,5.3496928215026855,5.316520690917969,5.606447219848633,5.943929672241211,5.72938871383667,5.401102066040039,5.356969833374023,5.7154107093811035,5.4715576171875,5.6655778884887695,5.5365824699401855,5.608362197875977,5.022561550140381,5.360151290893555,5.500790119171143,5.715410232543945,5.710937976837158,5.677332878112793,5.1941680908203125,5.40716552734375,5.630556106567383,5.430800437927246,5.6321516036987305,5.5327630043029785,5.3047308921813965,5.382503032684326,4.960195064544678,5.501653671264648,5.211460113525391],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"variable=val_loss<br>index=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"val_loss\",\"line\":{\"color\":\"#EF553B\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"val_loss\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"xaxis\":\"x\",\"y\":[5.1913580894470215,5.252114772796631,5.269052028656006,5.273106098175049,5.2953596115112305,5.276862144470215,5.349104881286621,5.332035064697266,5.298107147216797,5.305034637451172,5.303948402404785,5.27307653427124,5.283982276916504,5.2764458656311035,5.285111427307129,5.293612480163574,5.300595760345459,5.2985639572143555,5.349205017089844,5.347469329833984,5.360245227813721,5.327046871185303,5.32708740234375,5.324634075164795,5.3280510902404785,5.379393100738525,5.34151029586792,5.3641228675842285,5.396997451782227,5.3703508377075195,5.367498874664307,5.3625569343566895,5.404601573944092,5.432514667510986,5.446477890014648,5.42357063293457,5.445534706115723,5.4513068199157715,5.4419779777526855,5.441244125366211,5.4190449714660645,5.412721633911133,5.442285537719727,5.4822678565979,5.560856342315674,5.560156345367432,5.5656609535217285,5.558964729309082,5.5732316970825195,5.569182872772217,5.593746185302734,5.606201171875,5.614657878875732,5.683091163635254,5.724790096282959,5.741708278656006,5.782130241394043,5.760013103485107,5.763869762420654,5.791295528411865,5.798027992248535,5.8213725090026855,5.810747146606445,5.8159074783325195,5.801923751831055,5.76926851272583,5.723153591156006,5.714878082275391,5.6950225830078125,5.693704128265381,5.684196472167969,5.696015357971191,5.708759307861328,5.737916469573975,5.692381381988525,5.660266876220703,5.759631156921387,5.742620944976807,5.764825344085693,5.779759883880615,5.76856803894043,5.774596691131592,5.757667541503906,5.747600555419922,5.765483856201172,5.772540092468262,5.790256500244141,5.758791446685791,5.766707897186279,5.759646892547607,5.748678207397461,5.771238803863525,5.847263336181641,5.847992897033691,5.845649719238281,5.8265581130981445,5.836527347564697,5.874425411224365,5.896132469177246,5.903347492218018],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('51daeeec-89f9-4568-97d5-74b9942b20d6');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "px.line(losses[['loss','val_loss']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgT3Pgm1mdZR"
      },
      "outputs": [],
      "source": [
        "px.line(losses[['mean_absolute_percentage_error','val_mean_absolute_percentage_error']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ad_1fNp_miRh"
      },
      "outputs": [],
      "source": [
        "y5 = model.evaluate(x_test_encoded,  y_test, verbose=2)\n",
        "predictor = model.predict(x_test_encoded,verbose=0)\n",
        "PredictionDf = pd.DataFrame(predictor)\n",
        "PredictionDf['actual']=y_test\n",
        "PredictionDf = PredictionDf.rename(columns={0:'predicted'})\n",
        "PredictionDf.describe()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Dataset Explorer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}